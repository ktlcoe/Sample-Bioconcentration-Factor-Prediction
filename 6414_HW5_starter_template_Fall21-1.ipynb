{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "classified-greensboro",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Selected molecular descriptors from the Dragon chemoinformatics application were used to predict bioconcentration factors for 779 chemicals in order to evaluate QSAR (Quantitative Structure Activity Relationship).  This dataset was obtained from the UCI machine learning repository.\n",
    "\n",
    "The dataset consists of 779 observations of 10 attributes. Below is a brief description of each feature and the response variable (logBCF) in our dataset:\n",
    "\n",
    "1. *nHM* - number of heavy atoms (integer)\n",
    "2. *piPC09* - molecular multiple path count (numeric)\n",
    "3. *PCD* - difference between multiple path count and path count (numeric)\n",
    "4. *X2Av* - average valence connectivity (numeric)\n",
    "5. *MLOGP* - Moriguchi octanol-water partition coefficient (numeric)\n",
    "6. *ON1V* -  overall modified Zagreb index by valence vertex degrees (numeric)\n",
    "7. *N.072* - Frequency of RCO-N< / >N-X=X fragments (integer)\n",
    "8. *B02[C-N]* - Presence/Absence of C-N atom pairs (binary)\n",
    "9. *F04[C-O]* - Frequency of C-O atom pairs (integer)\n",
    "10. *logBCF* - Bioconcentration Factor in log units (numeric)\n",
    "\n",
    "Note that all predictors with the exception of B02[C-N] are quantitative.  For the purpose of this assignment, DO NOT CONVERT B02[C-N] to factor.  Leave the data in its original format - numeric in R.\n",
    "\n",
    "Please load the dataset \"Bio_pred\" and then split the dataset into a train and test set in a 80:20 ratio.\n",
    "\n",
    "Please make sure that you are using R version 3.6.X or above (i.e. version 4.X is also acceptable).\n",
    "\n",
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "developed-excellence",
   "metadata": {
    "message": false,
    "warning": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'leaps' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'glmnet' was built under R version 3.6.3\"Loading required package: Matrix\n",
      "Loaded glmnet 4.1-1\n"
     ]
    }
   ],
   "source": [
    "# Clear variables in memory\n",
    "rm(list=ls())\n",
    "\n",
    "# Import the libraries\n",
    "library(CombMSC)\n",
    "library(boot)\n",
    "library(leaps)\n",
    "library(MASS)\n",
    "library(glmnet)\n",
    "\n",
    "# Ensure that the sampling type is correct\n",
    "RNGkind(sample.kind=\"Rejection\")\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "set.seed(100)\n",
    "\n",
    "# Read data\n",
    "fullData = read.csv(\"Bio_pred.csv\",header=TRUE)\n",
    "\n",
    "# Split data for traIning and testing\n",
    "testRows = sample(nrow(fullData),0.2*nrow(fullData))\n",
    "testData = fullData[testRows, ]\n",
    "trainData = fullData[-testRows, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080db098",
   "metadata": {},
   "source": [
    "Note: Use the training set to build the models in Questions 1-6. Use the test set to help evaluate model performance in Question 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-citation",
   "metadata": {},
   "source": [
    "## Question 1: Full Model\n",
    "\n",
    "(a) Fit a multiple linear regression with the variable *logBCF* as the response and the other variables as predictors. Call it *model1*. Display the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "liable-stopping",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = logBCF ~ ., data = trainData)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.2577 -0.5180  0.0448  0.5117  4.0423 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.001422   0.138057   0.010  0.99179    \n",
       "nHM          0.137022   0.022462   6.100 1.88e-09 ***\n",
       "piPC09       0.031158   0.020874   1.493  0.13603    \n",
       "PCD          0.055655   0.063874   0.871  0.38391    \n",
       "X2Av        -0.031890   0.253574  -0.126  0.89996    \n",
       "MLOGP        0.506088   0.034211  14.793  < 2e-16 ***\n",
       "ON1V         0.140595   0.066810   2.104  0.03575 *  \n",
       "N.072       -0.073334   0.070993  -1.033  0.30202    \n",
       "B02.C.N.    -0.158231   0.080143  -1.974  0.04879 *  \n",
       "F04.C.O.    -0.030763   0.009667  -3.182  0.00154 ** \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.7957 on 614 degrees of freedom\n",
       "Multiple R-squared:  0.6672,\tAdjusted R-squared:  0.6623 \n",
       "F-statistic: 136.8 on 9 and 614 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = lm(logBCF ~ ., data=trainData)\n",
    "summary(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-minister",
   "metadata": {},
   "source": [
    "(b) Which regression coefficients are significant at the 95% confidence level? At the 99% confidence level?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752a2b0",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "At the 95% confidence level: nHM, MLOGP, ON1V, B02.C.N, F04.C.O<br>\n",
    "At the 99% Confidence level: nHM, MLOGP, ON1V, B02.C.N, F04.C.O\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-effects",
   "metadata": {},
   "source": [
    "(c) What are the Mallow's Cp, AIC, and BIC criterion values for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "whole-cocktail",
   "metadata": {
    "lines_to_next_cell": 2,
    "message": false,
    "warning": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'CP: '</li>\n",
       "\t<li>'-603.371048508102'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'CP: '\n",
       "\\item '-603.371048508102'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'CP: '\n",
       "2. '-603.371048508102'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"CP: \"              \"-603.371048508102\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'AIC: '</li>\n",
       "\t<li>'1497.47653274345'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'AIC: '\n",
       "\\item '1497.47653274345'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'AIC: '\n",
       "2. '1497.47653274345'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"AIC: \"            \"1497.47653274345\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "library(CombMSC)\n",
    "c(\"CP: \", Cp(model1, S2=24.86^2))\n",
    "c(\"AIC: \", AIC(model1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-nevada",
   "metadata": {},
   "source": [
    "(d) Build a new model on the training data with only the variables which coefficients were found to be statistically significant at the 99% confidence level. Call it *model2*. Perform a Partial F-test to compare this new model (*model2*) with the full model (*model1*). Which one would you prefer? Is it good practice to select variables based on statistical significance of individual coefficients? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "announced-marijuana",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = logBCF ~ nHM + MLOGP + ON1V + B02.C.N. + F04.C.O., \n",
       "    data = trainData)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.4897 -0.5157  0.0361  0.5436  4.0525 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -0.035709   0.097138  -0.368   0.7133    \n",
       "nHM          0.124981   0.019202   6.509 1.57e-10 ***\n",
       "MLOGP        0.569653   0.026171  21.767  < 2e-16 ***\n",
       "ON1V         0.129941   0.054767   2.373   0.0180 *  \n",
       "B02.C.N.    -0.119519   0.072402  -1.651   0.0993 .  \n",
       "F04.C.O.    -0.023428   0.009311  -2.516   0.0121 *  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.8002 on 618 degrees of freedom\n",
       "Multiple R-squared:  0.6612,\tAdjusted R-squared:  0.6585 \n",
       "F-statistic: 241.2 on 5 and 618 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "model2 = lm(logBCF ~ nHM + MLOGP + ON1V + B02.C.N. + F04.C.O., data=trainData)\n",
    "summary(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "closing-manhattan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Res.Df</th><th scope=col>RSS</th><th scope=col>Df</th><th scope=col>Sum of Sq</th><th scope=col>F</th><th scope=col>Pr(&gt;F)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>614       </td><td>388.7043  </td><td>NA        </td><td>       NA </td><td>      NA  </td><td>        NA</td></tr>\n",
       "\t<tr><td>618       </td><td>395.6696  </td><td>-4        </td><td>-6.965275 </td><td>2.750599  </td><td>0.02744663</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " Res.Df & RSS & Df & Sum of Sq & F & Pr(>F)\\\\\n",
       "\\hline\n",
       "\t 614        & 388.7043   & NA         &        NA  &       NA   &         NA\\\\\n",
       "\t 618        & 395.6696   & -4         & -6.965275  & 2.750599   & 0.02744663\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Res.Df | RSS | Df | Sum of Sq | F | Pr(>F) |\n",
       "|---|---|---|---|---|---|\n",
       "| 614        | 388.7043   | NA         |        NA  |       NA   |         NA |\n",
       "| 618        | 395.6696   | -4         | -6.965275  | 2.750599   | 0.02744663 |\n",
       "\n"
      ],
      "text/plain": [
       "  Res.Df RSS      Df Sum of Sq F        Pr(>F)    \n",
       "1 614    388.7043 NA        NA       NA         NA\n",
       "2 618    395.6696 -4 -6.965275 2.750599 0.02744663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(model1, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-south",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "p value is less than 0.05, so we can say that at least one of the coefficients removed from the model is non-zero. We thus prefer model1. It is not good practice to select variables based on statistical significance of individual coefficients because their impact may change depending on which variables are selected.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-moderator",
   "metadata": {},
   "source": [
    "## Question 2: Full Model Search\n",
    "\n",
    "(a) Compare all possible models using Mallow's Cp. What is the total number of possible models with the full set of variables? Display a table indicating the variables included in the best model of each size and the corresponding Mallow's Cp value. \n",
    "\n",
    "Hint: You can use nbest parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "otherwise-article",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>nHM</th><th scope=col>piPC09</th><th scope=col>PCD</th><th scope=col>X2Av</th><th scope=col>MLOGP</th><th scope=col>ON1V</th><th scope=col>N.072</th><th scope=col>B02.C.N.</th><th scope=col>F04.C.O.</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>0    </td><td>0.000</td><td>1.47 </td><td>0.14 </td><td>1.70 </td><td>0.88 </td><td>0    </td><td>1    </td><td>5    </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0    </td><td>0.000</td><td>1.20 </td><td>0.25 </td><td>4.14 </td><td>2.06 </td><td>0    </td><td>0    </td><td>0    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0    </td><td>0.000</td><td>1.69 </td><td>0.13 </td><td>1.89 </td><td>0.79 </td><td>0    </td><td>1    </td><td>8    </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0    </td><td>0.000</td><td>0.52 </td><td>0.25 </td><td>2.65 </td><td>1.31 </td><td>0    </td><td>0    </td><td>0    </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0    </td><td>0.000</td><td>1.40 </td><td>0.18 </td><td>2.85 </td><td>0.86 </td><td>0    </td><td>0    </td><td>0    </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>1    </td><td>3.446</td><td>1.23 </td><td>0.24 </td><td>2.01 </td><td>1.12 </td><td>0    </td><td>0    </td><td>7    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       "  & nHM & piPC09 & PCD & X2Av & MLOGP & ON1V & N.072 & B02.C.N. & F04.C.O.\\\\\n",
       "\\hline\n",
       "\t2 & 0     & 0.000 & 1.47  & 0.14  & 1.70  & 0.88  & 0     & 1     & 5    \\\\\n",
       "\t3 & 0     & 0.000 & 1.20  & 0.25  & 4.14  & 2.06  & 0     & 0     & 0    \\\\\n",
       "\t4 & 0     & 0.000 & 1.69  & 0.13  & 1.89  & 0.79  & 0     & 1     & 8    \\\\\n",
       "\t5 & 0     & 0.000 & 0.52  & 0.25  & 2.65  & 1.31  & 0     & 0     & 0    \\\\\n",
       "\t6 & 0     & 0.000 & 1.40  & 0.18  & 2.85  & 0.86  & 0     & 0     & 0    \\\\\n",
       "\t8 & 1     & 3.446 & 1.23  & 0.24  & 2.01  & 1.12  & 0     & 0     & 7    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | nHM | piPC09 | PCD | X2Av | MLOGP | ON1V | N.072 | B02.C.N. | F04.C.O. |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2 | 0     | 0.000 | 1.47  | 0.14  | 1.70  | 0.88  | 0     | 1     | 5     |\n",
       "| 3 | 0     | 0.000 | 1.20  | 0.25  | 4.14  | 2.06  | 0     | 0     | 0     |\n",
       "| 4 | 0     | 0.000 | 1.69  | 0.13  | 1.89  | 0.79  | 0     | 1     | 8     |\n",
       "| 5 | 0     | 0.000 | 0.52  | 0.25  | 2.65  | 1.31  | 0     | 0     | 0     |\n",
       "| 6 | 0     | 0.000 | 1.40  | 0.18  | 2.85  | 0.86  | 0     | 0     | 0     |\n",
       "| 8 | 1     | 3.446 | 1.23  | 0.24  | 2.01  | 1.12  | 0     | 0     | 7     |\n",
       "\n"
      ],
      "text/plain": [
       "  nHM piPC09 PCD  X2Av MLOGP ON1V N.072 B02.C.N. F04.C.O.\n",
       "2 0   0.000  1.47 0.14 1.70  0.88 0     1        5       \n",
       "3 0   0.000  1.20 0.25 4.14  2.06 0     0        0       \n",
       "4 0   0.000  1.69 0.13 1.89  0.79 0     1        8       \n",
       "5 0   0.000  0.52 0.25 2.65  1.31 0     0        0       \n",
       "6 0   0.000  1.40 0.18 2.85  0.86 0     0        0       \n",
       "8 1   3.446  1.23 0.24 2.01  1.12 0     0        7       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(trainData[,-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "opponent-drain",
   "metadata": {
    "lines_to_next_cell": 2,
    "message": false,
    "warning": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>1</th><th scope=col>2</th><th scope=col>3</th><th scope=col>4</th><th scope=col>5</th><th scope=col>6</th><th scope=col>7</th><th scope=col>8</th><th scope=col>9</th><th scope=col></th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>1        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>58.596851</td></tr>\n",
       "\t<tr><td>1        </td><td>0        </td><td>0        </td><td>0        </td><td>1        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>17.737801</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0        </td><td>0        </td><td>1        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>15.184626</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0        </td><td>0        </td><td>1        </td><td>0        </td><td>0        </td><td>0        </td><td>1        </td><td> 9.495041</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0        </td><td>0        </td><td>1        </td><td>0        </td><td>0        </td><td>1        </td><td>1        </td><td> 7.240754</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0        </td><td>0        </td><td>1        </td><td>1        </td><td>0        </td><td>1        </td><td>1        </td><td> 6.116174</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>0        </td><td>0        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td> 6.831852</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>1        </td><td>0        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td> 8.015816</td></tr>\n",
       "\t<tr><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>1        </td><td>10.000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & \\\\\n",
       "\\hline\n",
       "\t 0         & 0         & 0         & 0         & 1         & 0         & 0         & 0         & 0         & 58.596851\\\\\n",
       "\t 1         & 0         & 0         & 0         & 1         & 0         & 0         & 0         & 0         & 17.737801\\\\\n",
       "\t 1         & 1         & 0         & 0         & 1         & 0         & 0         & 0         & 0         & 15.184626\\\\\n",
       "\t 1         & 1         & 0         & 0         & 1         & 0         & 0         & 0         & 1         &  9.495041\\\\\n",
       "\t 1         & 1         & 0         & 0         & 1         & 0         & 0         & 1         & 1         &  7.240754\\\\\n",
       "\t 1         & 1         & 0         & 0         & 1         & 1         & 0         & 1         & 1         &  6.116174\\\\\n",
       "\t 1         & 1         & 0         & 0         & 1         & 1         & 1         & 1         & 1         &  6.831852\\\\\n",
       "\t 1         & 1         & 1         & 0         & 1         & 1         & 1         & 1         & 1         &  8.015816\\\\\n",
       "\t 1         & 1         & 1         & 1         & 1         & 1         & 1         & 1         & 1         & 10.000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |  |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0         | 0         | 0         | 0         | 1         | 0         | 0         | 0         | 0         | 58.596851 |\n",
       "| 1         | 0         | 0         | 0         | 1         | 0         | 0         | 0         | 0         | 17.737801 |\n",
       "| 1         | 1         | 0         | 0         | 1         | 0         | 0         | 0         | 0         | 15.184626 |\n",
       "| 1         | 1         | 0         | 0         | 1         | 0         | 0         | 0         | 1         |  9.495041 |\n",
       "| 1         | 1         | 0         | 0         | 1         | 0         | 0         | 1         | 1         |  7.240754 |\n",
       "| 1         | 1         | 0         | 0         | 1         | 1         | 0         | 1         | 1         |  6.116174 |\n",
       "| 1         | 1         | 0         | 0         | 1         | 1         | 1         | 1         | 1         |  6.831852 |\n",
       "| 1         | 1         | 1         | 0         | 1         | 1         | 1         | 1         | 1         |  8.015816 |\n",
       "| 1         | 1         | 1         | 1         | 1         | 1         | 1         | 1         | 1         | 10.000000 |\n",
       "\n"
      ],
      "text/plain": [
       "  1 2 3 4 5 6 7 8 9          \n",
       "1 0 0 0 0 1 0 0 0 0 58.596851\n",
       "2 1 0 0 0 1 0 0 0 0 17.737801\n",
       "3 1 1 0 0 1 0 0 0 0 15.184626\n",
       "4 1 1 0 0 1 0 0 0 1  9.495041\n",
       "5 1 1 0 0 1 0 0 1 1  7.240754\n",
       "6 1 1 0 0 1 1 0 1 1  6.116174\n",
       "7 1 1 0 0 1 1 1 1 1  6.831852\n",
       "8 1 1 1 0 1 1 1 1 1  8.015816\n",
       "9 1 1 1 1 1 1 1 1 1 10.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "library(leaps)\n",
    "out = leaps(trainData[,-10], trainData[,10], method = \"Cp\", nbest=1)\n",
    "cbind(as.matrix(out$which),out$Cp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-humanitarian",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "There are 2^9 total possible models with the full set of variables\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-scanning",
   "metadata": {},
   "source": [
    "(b) How many variables are in the model with the lowest Mallow's Cp value? Which variables are they? Fit this model and call it *model3*. Display the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "lovely-tender",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = logBCF ~ nHM + piPC09 + MLOGP + ON1V + B02.C.N. + \n",
       "    F04.C.O., data = trainData)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.2364 -0.5234  0.0421  0.5196  4.1159 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.035785   0.099454   0.360  0.71911    \n",
       "nHM          0.124086   0.019083   6.502 1.63e-10 ***\n",
       "piPC09       0.042167   0.014135   2.983  0.00297 ** \n",
       "MLOGP        0.528522   0.029434  17.956  < 2e-16 ***\n",
       "ON1V         0.098099   0.055457   1.769  0.07740 .  \n",
       "B02.C.N.    -0.160204   0.073225  -2.188  0.02906 *  \n",
       "F04.C.O.    -0.028644   0.009415  -3.042  0.00245 ** \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.7951 on 617 degrees of freedom\n",
       "Multiple R-squared:  0.666,\tAdjusted R-squared:  0.6628 \n",
       "F-statistic: 205.1 on 6 and 617 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "model3 = lm(logBCF ~ nHM + piPC09 + MLOGP + ON1V + B02.C.N. + F04.C.O., data=trainData)\n",
    "summary(model3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-canadian",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "There are 6 variables in the model with the lowest Mallow's CP value:  nHM + piPC09 + MLOGP + ON1V + B02.C.N. + F04.C.O.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-distinction",
   "metadata": {},
   "source": [
    "## Question 3: Stepwise Regression\n",
    "\n",
    "(a) Perform backward stepwise regression using BIC. Allow the minimum model to be the model with only an intercept, and the full model to be *model1*. Display the model summary of your final model. Call it *model4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "romance-appearance",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  AIC=-279.21\n",
      "logBCF ~ nHM + piPC09 + MLOGP + ON1V + B02.C.N. + F04.C.O.\n",
      "\n",
      "           Df Sum of Sq    RSS      AIC\n",
      "<none>                  390.04 -279.212\n",
      "- ON1V      1     1.978 392.02 -278.055\n",
      "- B02.C.N.  1     3.026 393.07 -276.390\n",
      "- piPC09    1     5.626 395.67 -272.276\n",
      "- F04.C.O.  1     5.851 395.89 -271.921\n",
      "- nHM       1    26.728 416.77 -239.853\n",
      "- MLOGP     1   203.819 593.86  -18.889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = logBCF ~ nHM + piPC09 + MLOGP + ON1V + B02.C.N. + \n",
       "    F04.C.O., data = trainData)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.2364 -0.5234  0.0421  0.5196  4.1159 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.035785   0.099454   0.360  0.71911    \n",
       "nHM          0.124086   0.019083   6.502 1.63e-10 ***\n",
       "piPC09       0.042167   0.014135   2.983  0.00297 ** \n",
       "MLOGP        0.528522   0.029434  17.956  < 2e-16 ***\n",
       "ON1V         0.098099   0.055457   1.769  0.07740 .  \n",
       "B02.C.N.    -0.160204   0.073225  -2.188  0.02906 *  \n",
       "F04.C.O.    -0.028644   0.009415  -3.042  0.00245 ** \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.7951 on 617 degrees of freedom\n",
       "Multiple R-squared:  0.666,\tAdjusted R-squared:  0.6628 \n",
       "F-statistic: 205.1 on 6 and 617 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "minimum <- glm(logBCF ~ 1, data=trainData)\n",
    "model4 = step(model3, scope=list(lower=minimum, upper=model1), direction = \"backward\")\n",
    "summary(model4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-experiment",
   "metadata": {},
   "source": [
    "(b) How many variables are in *model4*? Which regression coefficients are significant at the 99% confidence level?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c54c6d",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "Model 4 has 6 variables. Regression coefficients for nHM, piPC09, MLOGP, B02.C.N and F04.C.O are significant at the 99% level\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-telling",
   "metadata": {},
   "source": [
    "(c) Perform forward stepwise selection with AIC. Allow the minimum model to be the model with only an intercept, and the full model to be *model1*. Display the model summary of your final model. Call it *model5*. Do the variables included in *model5* differ from the variables in *model4*? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "nominated-seeker",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  AIC=-279.21\n",
      "logBCF ~ nHM + piPC09 + MLOGP + ON1V + B02.C.N. + F04.C.O.\n",
      "\n",
      "        Df Sum of Sq    RSS     AIC\n",
      "<none>               390.04 -279.21\n",
      "+ N.072  1   0.81306 389.23 -278.51\n",
      "+ PCD    1   0.66238 389.38 -278.27\n",
      "+ X2Av   1   0.02794 390.02 -277.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = logBCF ~ nHM + piPC09 + MLOGP + ON1V + B02.C.N. + \n",
       "    F04.C.O., data = trainData)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.2364 -0.5234  0.0421  0.5196  4.1159 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.035785   0.099454   0.360  0.71911    \n",
       "nHM          0.124086   0.019083   6.502 1.63e-10 ***\n",
       "piPC09       0.042167   0.014135   2.983  0.00297 ** \n",
       "MLOGP        0.528522   0.029434  17.956  < 2e-16 ***\n",
       "ON1V         0.098099   0.055457   1.769  0.07740 .  \n",
       "B02.C.N.    -0.160204   0.073225  -2.188  0.02906 *  \n",
       "F04.C.O.    -0.028644   0.009415  -3.042  0.00245 ** \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.7951 on 617 degrees of freedom\n",
       "Multiple R-squared:  0.666,\tAdjusted R-squared:  0.6628 \n",
       "F-statistic: 205.1 on 6 and 617 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "model5 = step(model3, scope=list(lower=minimum, upper=model1), direction = \"forward\")\n",
    "summary(model5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-marsh",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "Model 5 has 6 variables. Regression coefficients for nHM, piPC09, MLOGP, B02.C.N and F04.C.O are significant at the 99% level\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-anaheim",
   "metadata": {},
   "source": [
    "(d) Compare the adjusted $R^2$, Mallow's Cp, AICs and BICs of the full model (*model1*), the model found in Question 2 (*model3*), and the model found using backward selection with BIC (*model4*). Which model is preferred based on these criteria and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-repository",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "set.seed(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-benjamin",
   "metadata": {},
   "source": [
    "## Question 4: Ridge Regression\n",
    "\n",
    "(a) Perform ridge regression on the training set. Use cv.glmnet() to find the lambda value that minimizes the cross-validation error using 10 fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "tough-uncle",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.108775012396901"
      ],
      "text/latex": [
       "0.108775012396901"
      ],
      "text/markdown": [
       "0.108775012396901"
      ],
      "text/plain": [
       "[1] 0.108775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "library(MASS)\n",
    "train_cv = cv.glmnet(data.matrix(trainData[,-10]), trainData[,10], alpha=0, nfolds=10)\n",
    "model6 = glmnet(data.matrix(trainData[,-10]), trainData[,10], alpha=0, nlambda=100)\n",
    "train_cv$lambda.min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-amendment",
   "metadata": {},
   "source": [
    "(b) List the value of coefficients at the optimum lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cultural-logging",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                      1\n",
       "(Intercept)  0.13841426\n",
       "nHM          0.14391877\n",
       "piPC09       0.03735762\n",
       "PCD          0.08235334\n",
       "X2Av        -0.06901352\n",
       "MLOGP        0.44403654\n",
       "ON1V         0.15770114\n",
       "N.072       -0.09683534\n",
       "B02.C.N.    -0.20919397\n",
       "F04.C.O.    -0.03177144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "coef(model6, s=train_cv$lambda.min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-macintosh",
   "metadata": {},
   "source": [
    "(c) How many variables were selected? Was this result expected? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1733fd9",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "\n",
    "All variables were selected. This was unexpected as it does not match our forward of backwards regression.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-banner",
   "metadata": {},
   "source": [
    "## Question 5: Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-patient",
   "metadata": {},
   "source": [
    "(a) Perform lasso regression on the training set.Use cv.glmnet() to find the lambda value that minimizes the cross-validation error using 10 fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "forbidden-residence",
   "metadata": {
    "message": false,
    "warning": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.00785443587360036"
      ],
      "text/latex": [
       "0.00785443587360036"
      ],
      "text/markdown": [
       "0.00785443587360036"
      ],
      "text/plain": [
       "[1] 0.007854436"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "train_cv = cv.glmnet(data.matrix(trainData[,-10]), trainData[,10], alpha=1, nfolds=10)\n",
    "model7 = glmnet(data.matrix(trainData[,-10]), trainData[,10], alpha=1, nlambda=100)\n",
    "train_cv$lambda.min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-doctor",
   "metadata": {},
   "source": [
    "(b) Plot the regression coefficient path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "norwegian-procurement",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAAAP8AzQAA//9N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\nAgQQEiCAkAABhAQIICRAACEBAggJEPD/8rjcf8ak6AoAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "plot(model7,xvar=\"lambda\",label=TRUE,lwd=2)\n",
    "abline(v=log(train_cv$lambda.min),col='black',lty = 2,lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-shadow",
   "metadata": {},
   "source": [
    "(c) How many variables were selected? Which are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "several-strike",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                      1\n",
       "(Intercept)  0.02722838\n",
       "nHM          0.12543866\n",
       "piPC09       0.03387665\n",
       "PCD          0.03194878\n",
       "X2Av         .         \n",
       "MLOGP        0.52174346\n",
       "ON1V         0.09633951\n",
       "N.072       -0.05487196\n",
       "B02.C.N.    -0.13961811\n",
       "F04.C.O.    -0.02535576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "coef(model7, s=train_cv$lambda.min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-paris",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "8 variables are selected. All except for X2Av</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-vintage",
   "metadata": {},
   "source": [
    "## Question 6: Elastic Net\n",
    "\n",
    "(a) Perform elastic net regression on the training set. Use cv.glmnet() to find the lambda value that minimizes the cross-validation error using 10 fold CV. Give equal weight to both penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "helpful-extra",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0207662039532022"
      ],
      "text/latex": [
       "0.0207662039532022"
      ],
      "text/markdown": [
       "0.0207662039532022"
      ],
      "text/plain": [
       "[1] 0.0207662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "train_cv = cv.glmnet(data.matrix(trainData[,-10]), trainData[,10], alpha=0.5, nfolds=10)\n",
    "model8 = glmnet(data.matrix(trainData[,-10]), trainData[,10], alpha=0.5, nlambda=100)\n",
    "train_cv$lambda.min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-onion",
   "metadata": {},
   "source": [
    "(b) List the coefficient values at the optimal lambda. How many variables were selected? How do these variables compare to those from Lasso in Question 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "valuable-seattle",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                      1\n",
       "(Intercept)  0.04903516\n",
       "nHM          0.12397290\n",
       "piPC09       0.03470891\n",
       "PCD          0.03060034\n",
       "X2Av         .         \n",
       "MLOGP        0.51776470\n",
       "ON1V         0.08901088\n",
       "N.072       -0.05236840\n",
       "B02.C.N.    -0.14155538\n",
       "F04.C.O.    -0.02420217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(100)\n",
    "set.seed(100)\n",
    "coef(model8, s=train_cv$lambda.min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-promise",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "All variables except for X2Av were selected. This matches lasso from Q5\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-teacher",
   "metadata": {},
   "source": [
    "## Question 7: Model comparison\n",
    "\n",
    "(a) Predict *logBCF* for each of the rows in the test data using the full model, and the models found using backward stepwise regression with BIC, ridge regression, lasso regression, and elastic net. Display the first few predictions for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "limited-taste",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>fit</th><th scope=col>lwr</th><th scope=col>upr</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>714</th><td>2.446479  </td><td>0.87707975</td><td>4.015878  </td></tr>\n",
       "\t<tr><th scope=row>503</th><td>4.333759  </td><td>2.76395272</td><td>5.903565  </td></tr>\n",
       "\t<tr><th scope=row>358</th><td>3.266892  </td><td>1.69926856</td><td>4.834515  </td></tr>\n",
       "\t<tr><th scope=row>624</th><td>1.664770  </td><td>0.06548615</td><td>3.264053  </td></tr>\n",
       "\t<tr><th scope=row>718</th><td>1.955362  </td><td>0.38323014</td><td>3.527495  </td></tr>\n",
       "\t<tr><th scope=row>470</th><td>4.333278  </td><td>2.76342774</td><td>5.903128  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & fit & lwr & upr\\\\\n",
       "\\hline\n",
       "\t714 & 2.446479   & 0.87707975 & 4.015878  \\\\\n",
       "\t503 & 4.333759   & 2.76395272 & 5.903565  \\\\\n",
       "\t358 & 3.266892   & 1.69926856 & 4.834515  \\\\\n",
       "\t624 & 1.664770   & 0.06548615 & 3.264053  \\\\\n",
       "\t718 & 1.955362   & 0.38323014 & 3.527495  \\\\\n",
       "\t470 & 4.333278   & 2.76342774 & 5.903128  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | fit | lwr | upr |\n",
       "|---|---|---|---|\n",
       "| 714 | 2.446479   | 0.87707975 | 4.015878   |\n",
       "| 503 | 4.333759   | 2.76395272 | 5.903565   |\n",
       "| 358 | 3.266892   | 1.69926856 | 4.834515   |\n",
       "| 624 | 1.664770   | 0.06548615 | 3.264053   |\n",
       "| 718 | 1.955362   | 0.38323014 | 3.527495   |\n",
       "| 470 | 4.333278   | 2.76342774 | 5.903128   |\n",
       "\n"
      ],
      "text/plain": [
       "    fit      lwr        upr     \n",
       "714 2.446479 0.87707975 4.015878\n",
       "503 4.333759 2.76395272 5.903565\n",
       "358 3.266892 1.69926856 4.834515\n",
       "624 1.664770 0.06548615 3.264053\n",
       "718 1.955362 0.38323014 3.527495\n",
       "470 4.333278 2.76342774 5.903128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>fit</th><th scope=col>lwr</th><th scope=col>upr</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>714</th><td>2.454699  </td><td>0.88653029</td><td>4.022867  </td></tr>\n",
       "\t<tr><th scope=row>503</th><td>4.336886  </td><td>2.76823970</td><td>5.905532  </td></tr>\n",
       "\t<tr><th scope=row>358</th><td>3.279941  </td><td>1.71362219</td><td>4.846260  </td></tr>\n",
       "\t<tr><th scope=row>624</th><td>1.618796  </td><td>0.02539812</td><td>3.212194  </td></tr>\n",
       "\t<tr><th scope=row>718</th><td>1.924693  </td><td>0.35530889</td><td>3.494077  </td></tr>\n",
       "\t<tr><th scope=row>470</th><td>4.339247  </td><td>2.77057318</td><td>5.907921  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & fit & lwr & upr\\\\\n",
       "\\hline\n",
       "\t714 & 2.454699   & 0.88653029 & 4.022867  \\\\\n",
       "\t503 & 4.336886   & 2.76823970 & 5.905532  \\\\\n",
       "\t358 & 3.279941   & 1.71362219 & 4.846260  \\\\\n",
       "\t624 & 1.618796   & 0.02539812 & 3.212194  \\\\\n",
       "\t718 & 1.924693   & 0.35530889 & 3.494077  \\\\\n",
       "\t470 & 4.339247   & 2.77057318 & 5.907921  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | fit | lwr | upr |\n",
       "|---|---|---|---|\n",
       "| 714 | 2.454699   | 0.88653029 | 4.022867   |\n",
       "| 503 | 4.336886   | 2.76823970 | 5.905532   |\n",
       "| 358 | 3.279941   | 1.71362219 | 4.846260   |\n",
       "| 624 | 1.618796   | 0.02539812 | 3.212194   |\n",
       "| 718 | 1.924693   | 0.35530889 | 3.494077   |\n",
       "| 470 | 4.339247   | 2.77057318 | 5.907921   |\n",
       "\n"
      ],
      "text/plain": [
       "    fit      lwr        upr     \n",
       "714 2.454699 0.88653029 4.022867\n",
       "503 4.336886 2.76823970 5.905532\n",
       "358 3.279941 1.71362219 4.846260\n",
       "624 1.618796 0.02539812 3.212194\n",
       "718 1.924693 0.35530889 3.494077\n",
       "470 4.339247 2.77057318 5.907921"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in cbind2(1, newx) %*% nbeta: not-yet-implemented method for <data.frame> %*% <dgCMatrix>\n",
     "output_type": "error",
     "traceback": [
      "Error in cbind2(1, newx) %*% nbeta: not-yet-implemented method for <data.frame> %*% <dgCMatrix>\nTraceback:\n",
      "1. predict(model6, testData, interval = \"prediction\")",
      "2. predict.elnet(model6, testData, interval = \"prediction\")",
      "3. NextMethod(\"predict\")",
      "4. predict.glmnet(model6, testData, interval = \"prediction\")",
      "5. as.matrix(cbind2(1, newx) %*% nbeta)",
      "6. cbind2(1, newx) %*% nbeta",
      "7. cbind2(1, newx) %*% nbeta",
      "8. stop(gettextf(\"not-yet-implemented method for <%s> %%*%% <%s>\", \n .     class(x), class(y)), domain = NA)"
     ]
    }
   ],
   "source": [
    "set.seed(100)\n",
    "m1.pred <- predict(model1, testData, interval=\"prediction\")\n",
    "head(m1.pred)\n",
    "\n",
    "m4.pred <- predict(model4, testData, interval=\"prediction\")\n",
    "head(m4.pred)\n",
    "\n",
    "m6.pred <- predict(model6, testData, interval=\"prediction\")\n",
    "head(m6.pred)\n",
    "\n",
    "m7.pred <- predict(model7, testData, interval=\"prediction\")\n",
    "head(m7.pred)\n",
    "\n",
    "m8.pred <- predict(model8, testData, interval=\"prediction\")\n",
    "head(m8.pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-peninsula",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "double-permission",
   "metadata": {},
   "source": [
    "(b) Compare the predictions using mean squared prediction error. Which model performed the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "western-retirement",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2.23795456180647"
      ],
      "text/latex": [
       "2.23795456180647"
      ],
      "text/markdown": [
       "2.23795456180647"
      ],
      "text/plain": [
       "[1] 2.237955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2.23251407926269"
      ],
      "text/latex": [
       "2.23251407926269"
      ],
      "text/markdown": [
       "2.23251407926269"
      ],
      "text/plain": [
       "[1] 2.232514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in mean((testData$logBCF - m6.pred)^2): object 'm6.pred' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in mean((testData$logBCF - m6.pred)^2): object 'm6.pred' not found\nTraceback:\n",
      "1. mean((testData$logBCF - m6.pred)^2)"
     ]
    }
   ],
   "source": [
    "set.seed(100)\n",
    "mean((testData$logBCF - m1.pred)^2)\n",
    "mean((testData$logBCF - m4.pred)^2)\n",
    "mean((testData$logBCF - m6.pred)^2)\n",
    "mean((testData$logBCF - m7.pred)^2)\n",
    "mean((testData$logBCF - m8.pred)^2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-double",
   "metadata": {},
   "source": [
    "(c) Provide a table listing each method described in Question 7a and the variables selected by each method (see Lesson 5.8 for an example). Which variables were selected consistently?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-collector",
   "metadata": {},
   "source": [
    "|        | Backward Stepwise | Ridge | Lasso  | Elastic Net |\n",
    "|--------|-------------|-------------------|--------|-------|\n",
    "|nHM     |       x     |      x            |  x     |   x    |          \n",
    "|piPC09  |       x     |      x            |  x     |   x    | \n",
    "|PCD     |             |      x            |  x     |   x    |        \n",
    "|X2AV    |             |      x            |        |        | \n",
    "|MLOGP   |       x     |      x            |  x     |   x    | \n",
    "|ON1V    |       x     |      x            |  x     |   x    | \n",
    "|N.072   |             |      x            |  x     |   x    | \n",
    "|B02.C.N.|       x     |      x            |  x     |   x    |\n",
    "|F04.C.O.|       x     |      x            |  x     |   x    | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-place",
   "metadata": {},
   "source": [
    "<div style=\"background: lightblue; border: 3px solid black; margin: 3px; padding: 5px\">\n",
    "nHM, piPC09, MLOGP, ON1V, B02.C.N, and F04.C.O were consistently selected\n",
    "</div"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "name,tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
